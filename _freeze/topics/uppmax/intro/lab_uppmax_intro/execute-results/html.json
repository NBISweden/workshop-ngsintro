{
  "hash": "3f480f87e9134ae417de5515ff4bfd75",
  "result": {
    "markdown": "---\ntitle:  'Uppmax Introduction'\nsubtitle: \"High-performance computing cluster: UPPMAX\"\nauthor: 'Martin Dahl√∂'\nformat: html\n---\n\n\n\n\n::: {.callout-note}\nIn code blocks, the dollar sign (`$`) is not to be printed. The dollar sign is usually an indicator that the text following it should be typed in a terminal window.\n:::\n\n# Connect to UPPMAX\n\nThe first step of this lab is to open a ssh connection to UPPMAX. Please refer to [**Connecting to UPPMAX**](topics/other/lab_connect.html) for instructions. Once connected to UPPMAX, return here and continue reading the instructions below.\n\n# Logon to a node\n\nUsually you would do most of the work in this lab directly on one of the login nodes at UPPMAX, but we have arranged for you to have one core each for better performance. This was covered briefly in the lecture notes.\n\nCheck which node you got when you booked resources this morning (replace **username** with your UPPMAX username)\n\n```bash\n$ squeue -u username\n```\n\nshould look something like this\n\n```bash\ndahlo@rackham2 work $ squeue -u dahlo\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           3132376      core       sh    dahlo  R       0:04      1 r292\ndahlo@rackham2 work $\n```\n\nwhere **r292** is the name of the node I got (yours will probably be different).\nNote the numbers in the Time column. They show for how long the job has been running. When it reaches the time limit you requested (7 hours in this case) the session will shut down, and you will lose all unsaved data. Connect to this node from within UPPMAX.\n\n```bash\n$ ssh -Y r292\n```\n\nIf the list is empty you can run the allocation command again and it should be in the list:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.bash}\n$ salloc -A snic2023-xx-xxxx -t 03:30:00 -p core -n 1 --no-shell\n```\n:::\n:::\n\n\n{{< fa lightbulb >}} There is a UPPMAX specific tool called `jobinfo` that supplies the same kind of information as `squeue` that you can use as well (`$ jobinfo -u username`).\n\n# Copy files for lab\n\nNow, you will need some files. To avoid all the course participants editing the same file all at once, undoing each other's edits, each participant will get their own copy of the needed files. The files are located in the folder **/sw/courses/ngsintro/linux/uppmax_tutorial**\n\nNext, copy the lab files from this folder. `-r` means recursively, which means all the files including sub-folders of the source folder. Without it, only files directly in the source folder would be copied, NOT sub-folders and files in sub-folders.\n\n{{< fa lightbulb >}} Remember to use tab-complete to avoid typos and too much writing.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.bash}\n$ cp -r <source> <destination>\n$ cp -r /sw/courses/ngsintro/linux/uppmax_tutorial /proj/snic2023-xx-xxxx/nobackup/username\n```\n:::\n:::\n\n\nHave a look in **/proj/snic2023-xx-xxxx/nobackup/&lt;username&gt;/uppmax_tutorial**.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.bash}\n$ cd /proj/snic2023-xx-xxxx/nobackup/username/uppmax_tutorial\n```\n:::\n:::\n\n\n```\n$ ll\ntotal 128K\ndrwxrwxr-x 2 dahlo dahlo 2,0K May 18 16:21 .\ndrwxrwxr-x 4 dahlo dahlo 2,0K May 18 15:34 ..\n-rwxrwxr-x 1 dahlo dahlo 1,2K May 18 16:21 data.bam\n-rw-rw-r-- 1 dahlo dahlo  232 May 18 16:21 job_template\n$\n```\n\n# Run programs\n\nAmong the files that were copied is **data.bam**. BAM is a popular format to store aligned sequence data, but since it is a, so called, binary format it doesn't look that good if you are human. Try it using less:\n\n```bash\n$ less data.bam\n```\n\n![](assets/bam_binary.png)\n\nNot so pretty.. Luckily for us, there is a program called **[samtools](http://www.htslib.org/)** that is made for reading BAM files. To use it on UPPMAX we must first load the module for **samtools**. Try starting samtools before loading the module.\n\n```bash\n$ samtools\n-bash: samtools: command not found\n$\n\n```\n\nThat did not work, try it again after loading the module:\n\n```bash\n$ module load bioinfo-tools samtools/1.10\n$ samtools\n\nProgram: samtools (Tools for alignments in the SAM format)\nVersion: 1.10 (using htslib 1.10)\n\nUsage:   samtools <command> [options]\n\nCommands:\n  -- Indexing\n     dict           create a sequence dictionary file\n     faidx          index/extract FASTA\n     fqidx          index/extract FASTQ\n     index          index alignment\n\n  -- Editing\n     calmd          recalculate MD/NM tags and '=' bases\n     fixmate        fix mate information\n     reheader       replace BAM header\n     targetcut      cut fosmid regions (for fosmid pool only)\n     addreplacerg   adds or replaces RG tags\n     markdup        mark duplicates\n\n  -- File operations\n     collate        shuffle and group alignments by name\n     cat            concatenate BAMs\n     merge          merge sorted alignments\n     mpileup        multi-way pileup\n     sort           sort alignment file\n     split          splits a file by read group\n     quickcheck     quickly check if SAM/BAM/CRAM file appears intact\n     fastq          converts a BAM to a FASTQ\n     fasta          converts a BAM to a FASTA\n\n  -- Statistics\n     bedcov         read depth per BED region\n     coverage       alignment depth and percent coverage\n     depth          compute the depth\n     flagstat       simple stats\n     idxstats       BAM index stats\n     phase          phase heterozygotes\n     stats          generate stats (former bamcheck)\n\n  -- Viewing\n     flags          explain BAM flags\n     tview          text alignment viewer\n     view           SAM<->BAM<->CRAM conversion\n     depad          convert padded BAM to unpadded BAM\n\n```\n\n{{< fa exclamation-circle >}} All modules are unloaded when you disconnect from UPPMAX, so you will have to load the modules again every time you log in. If you load a module in a terminal window, it will not affect the modules you have loaded in another terminal window, even if both terminals are connected to UPPMAX. Each terminal is independent of the others.\n\nTo use samtools to view a BAM file, use the following line.\n\n```bash\n$ samtools view -h data.bam\n@HD\tVN:1.0\tSO:coordinate\n@SQ\tSN:chr1\tLN:249250621\n@SQ\tSN:chr10\tLN:135534747\n@SQ\tSN:chr11\tLN:135006516\n@SQ\tSN:chr12\tLN:133851895\n@SQ\tSN:chr13\tLN:115169878\n@SQ\tSN:chr14\tLN:107349540\n@SQ\tSN:chr15\tLN:102531392\n@SQ\tSN:chr16\tLN:90354753\n```\n\n**`-h`** also print the BAM file's **header**, which is the rows starting with **`@` signs** in the beginning of the file. These lines contain so called **metadata**; information about the data stored in the file. It contain things like which program was used to generate the BAM file and which chromosomes are present in the file. Try running the command without the **`-h`** to see the difference.\n\nThe not-binary version (ASCII, or text version) of a BAM file is called a **SAM file**, which was just printed directly into the terminal window. The SAM file is not to much use for us printed in the terminal window, aesthetics aside. It is probably much better to have the SAM file saved as an actual file, something that is very easy to do. Any text that is printed to the terminal can be saved to a file instead of the terminal window using a 'crocodile mouth', **`>`**\n\n```bash\n$ program arguments > outfile\n```\n\nwhich will launch a program named **program**, supply it with the argument **arguments**, and write any output that would have been printed to the screen to the file **outfile** instead.\n\nTo use this on samtools,\n\n```bash\n$ samtools view -h data.bam > data.sam\n```\n\nLook at the created file:\n\n```bash\n$ ll\n```\n\nThe SAM file is now human readable. Try viewing it with **`less`**:\n\n```bash\n$ less data.sam\n```\n\nYou can also edit the file with **nano**:\n\n```bash\n$ nano data.sam\n```\n\nTry deleting the whole last line in the file, save it, and exit nano.\n\n# Modules\n\nTo view which module you have loaded at the moment, type\n\n```bash\n$ module list\n\nCurrently Loaded Modules:\n  1) uppmax   2) bioinfo-tools   3) samtools/1.10\n```\n\nLet's say that you want to make sure you are using the latest version samtools. Look at which version you have loaded at the moment (`samtools/1.10`).\n\nNow type\n\n```bash\n$ module avail\n```\n\nto see which programs are available at UPPMAX. Can you find samtools in the list? Which is the latest version of samtools available at UPPMAX?\n\nTo change which samtools module you have loaded, you have to unload the the module you have loaded and then load the other module. To unload a module, use\n\n```bash\n$ module unload <module name>\n\n```\n\nLook in the list from `$ module list` to see the name of the module you want to unload. When the old module is unloaded, load `samtools/0.1.19` (or try with the latest samtools module!).\n\n# Submitting a job\n\nNot all jobs are as small as converting this tiny BAM file to a SAM file. Usually the BAM files are several gigabytes, and can take hours to convert to SAM files. You will not have reserved nodes waiting for you to do something either, so running programs is done by submitting a job to the queue system. What you submit to the queue system is a script file that will be executed as soon as it reaches the front of the queue. The scripting language used in these scripts is **bash**, which is the same language as you usually use in a terminal i.e. everything so far in the lecture and lab has been in the bash language (`cd`, `ls`, `cp`, `mv`, etc.).\n\nHave a look at **job_template** in your **uppmax_tutorial** folder.\n\n```bash\n$ less job_template\n\n#! /bin/bash -l\n#SBATCH -A gXXXXXXX\n#SBATCH -p core\n#SBATCH -J Template_script\n#SBATCH -t 01:00:00\n\n# load some modules\nmodule load bioinfo-tools\n\n# go to some directory\ncd /proj/gXXXXXXX/nobackup/\n\n# do something\necho Hello world!\n```\n\nEdit this file to make the job convert **data.bam** to a SAM file named **jobData.sam**. Remember how the queue works? Try to approximate the runtime of the job (almost instant in this case) and increase it by ~50%, and use that time approximation when writing your script file. Longer jobs will wait longer in the queue because it is harder to fit them into gaps in the queue! Also remember to change the project ID to match this course occasion.\n\nRemember, just write the command you would run if you were sitting by the computer, i.e. load the correct modules, go to the correct folder, and run samtools the right way.\n\n{{< fa clipboard-list >}} Submit your job using `sbatch`:\n\n```bash\n$ sbatch job_template\n```\n\n# Job queue\n\nIf you want to know how your jobs are doing in the queue, you can check their status with `$ squeue -u username` or `$ jobinfo -u username`.\n\nRewrite the previous sbatch file so that you book 3 days of time, and to use a node instead of a core. This will cause your job to stand in the queue for a bit longer, so that we can have a look at it while it is queuing. Submit it to the queue and run **`jobinfo`**.\n\n```bash\n$ jobinfo -u username\n\nCLUSTER: rackham\nRunning jobs:\n   JOBID PARTITION                      NAME     USER        ACCOUNT ST          START_TIME  TIME_LEFT  NODES CPUS NODELIST(REASON)\n 3134399   devcore                               dahlo       g20XXXXX  R 2018-05-18T16:32:54      59:25      1    1 r483\n\nNodes in use:                            462\nNodes in devel, free to use:               2\nNodes in other partitions, free to use:    4\nNodes available, in total:               468\n\nNodes in test and repair:                 13\nNodes, otherwise out of service:           5\nNodes, all in total:                     486\n\nWaiting jobs:\n   JOBID    POS PARTITION                      NAME     USER        ACCOUNT ST          START_TIME   TIME_LEFT PRIORITY CPUS NODELIST(REASON)     FEATURES DEPENDENCY\n 3134401    221      core           Template_script    dahlo       g20XXXXX PD                 N/A     1:00:00   100000    1           (None)       (null)\n\nWaiting bonus jobs:\n$\n\n```\n\nIf you look under the heading **\"Waiting jobs:\"** you'll see a list of all the jobs you have in the queue that have not started yet. The most interesting column here is the **POS** column, which tells you which position in the queue you have (221 in my example). When you reach the first place, your job will start as soon as there are the resources you have asked for.\n\nIn our case, we are not really interested in running this job at all. Let's cancel it instead. This can be done with the command **`scancel`**. Syntax:\n\n```bash\n$ scancel <job id>\n```\n\nYou see the job id number in the output from `jobinfo` or `squeue`.\n\n```bash\n$ scancel 3134401\n```\n\n# Interactive jobs\n\nSometimes it is more convenient to work interactively on a node instead of submitting your work as a job. Since you will not have the reservations we have during the course, you will have to book a node using the **`interactive`** command. Syntax:\n\n```bash\n$ interactive -A <project id> -t <time> -p <node or core>\n```\n\nThis will create a booking for you which has a higher priority than the jobs submitted with `sbatch`. That means that they will start faster, but only if the booking is shorter than 12 hours. If the booking is longer than 12 hours, it will get the standard priority. When the job starts you will be transferred to the node you got automatically. No need to look which node you got using sbatch and then ssh:ing to it.\n\nTry closing down your current session on the reserved node you connected to in the beginning of the lab by typing `exit`. Then make a new booking using interactive,\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.bash}\n$ interactive -A snic2023-xx-xxxx -t 02:30:00 -p core\n```\n:::\n:::\n\n\nCongratulations, you are now ready to be let loose on the cluster!\n\n# Extra\n\nExtra material if you finish too fast.\n\n## The devel queue\n\nIf it is a really big job, it might be in the queue for a day or two before it starts, so it is important to know that the first thing it does is not crashing because you made a typo on line 7. One way to test this is to open a new connection to UPPMAX, and line by line try your code. Copy-paste (<kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>c</kbd> and <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>v</kbd> in the terminal window) to make sure it's really the code in the script you are trying.\n\nIf your script is longer than a couple of lines, this approach can be tiring. There are 12 nodes at UPPMAX that are dedicated to do quick test runs, which have a separate queue called **devel**. They are available for use more or less all the time since not very many are using them. To avoid people abusing the free nodes for their analysis, there is a **1 hour time limit** for jobs on them. To submit jobs to this short testing queue, change `-p` to devel instead of node or core, and make sure `-t` is set to **maximum 01:00:00**. Try submitting the samtools sbatch file we used earlier to the devel queue and run it again.\n\n## Info about finished jobs\n\nIf you want information about jobs you have run in the past, you can use the tool **`finishedjobinfo`**. It will print information about the jobs you have run lately.\n\nFun things to look for in this information is **jobstate** which will tell you if the program reported any error while running. If so, jobstate will be **FAILED** and you could suspect that something didn't go according to the plan, and you should check the output from that job run (the **slurm-.out** file) and see if you can solve the error.\n\nOther good things to look for could be:\n\n* **maxmemory\\_in\\_GiB**: tells you how much memory the program used at most.\n* **runtime**: tells you how long time the program ran before it finished/failed\n\n## Time and space\n\nRemember the commands **`uquota`** (show how much of your storage space you are using) and **`projinfo`** (shows you how much of your allocated time you have used) from the lecture? Try running them and see how you are doing.\n\n\n::: {.callout-tip}\n\n## Optional\n\nThis optional material on uppmax pipelines will teach you the basics in creating pipelines. Continue with this if you finish the current lab ahead of time. Navigate to the exercise [Uppmax Pipelines lab](topics/uppmax/pipeline/lab_uppmax_pipeline.html).\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}