{"title":"Filetypes","markdown":{"yaml":{"title":"Filetypes","subtitle":"Common filetypes In bioinformatics","author":"Martin Dahl√∂","format":"html"},"headingText":"Connect to UPPMAX","containsRefs":false,"markdown":"\n\n```{r,eval=TRUE,include=FALSE}\nlibrary(yaml)\nlibrary(here)\nupid <- yaml::read_yaml(here(\"_quarto.yml\"))$uppmax_project\n```\n\n::: {.callout-note}\nIn code blocks, the dollar sign (`$`) is not to be printed. The dollar sign is usually an indicator that the text following it should be typed in a terminal window.\n:::\n\n\nThe first step of this lab is to open a ssh connection to UPPMAX. Please refer to [**Connecting to UPPMAX**](topics/other/lab_connect.html) for instructions. Once connected to UPPMAX, return here and continue reading the instructions below.\n\n## Logon to a node\n\nUsually you would do most of the work in this lab directly on one of the login nodes at UPPMAX, but we have arranged for you to have one core each for better performance. This was covered briefly in the lecture notes.\n\n```{r,echo=FALSE,comment=\"\",class.output=\"bash\"}\ncat(paste0(\"$ salloc -A \",upid,\" -t 07:00:00 -p core -n 1 --no-shell &\"))\n```\n\ncheck which node you got (replace **username** with your UPPMAX username)\n\n```bash\n$ squeue -u username\n```\n\nshould look something like this\n\n```bash\ndahlo@rackham2 work $ squeue -u dahlo\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           3132376      core       sh    dahlo  R       0:04      1 r292\ndahlo@rackham2 work $\n```\n\nwhere **r292** is the name of the node I got (yours will probably be different).\nNote the numbers in the Time column. They show for how long the job has been running. When it reaches the time limit you requested (7 hours in this case) the session will shut down, and you will lose all unsaved data. Connect to this node from within UPPMAX.\n\n```bash\n$ ssh -Y r292\n```\n\n{{< fa lightbulb >}} There is a UPPMAX specific tool called `jobinfo` that supplies the same kind of information as `squeue` that you can use as well (`$ jobinfo -u username`).\n\n## Copy lab files\n\nNow you will need some files. To avoid all the course participants editing the same file all at once, undoing each other's edits, each participant will get their own copy of the needed files. The files are located in the folder `/sw/courses/ngsintro/linux/filetypes`\n\nNext, copy the lab files from this folder. `-r` means recursively, which means all the files including sub-folders of the source folder. Without it, only files directly in the source folder would be copied, NOT sub-folders and files in sub-folders.\n\n{{< fa lightbulb >}} Remember to use tab-complete to avoid typos and too much writing.\n\n```{r,echo=FALSE,comment=\"\",class.output=\"bash\"}\ncat(\"$ cp -r <source> <destination>\\n\")\ncat(paste0(\"$ cp -r /sw/courses/ngsintro/linux/filetypes /proj/\",upid,\"/nobackup/username/\"))\n```\n\nHave a look in **`r paste0(\"/proj/\",upid,\"/nobackup/username/\")`**.\n\n```{r,echo=FALSE,comment=\"\",class.output=\"bash\"}\ncat(paste0(\"$ cd /proj/\",upid,\"/nobackup/username/filetypes\\n\"))\ncat(\"$ tree\")\n```\n\nThis will print a file tree, which gives you a nice overview of the folders where you are standing in. As you can see, you have a couple of files and a couple of empty folders. In the **0_ref** folder you have a reference genome in fasta format and annotations for the genome in GTF format. In **0_seq** you have a fastq file containing the reads we will align.\n\n## Run pipeline\n\nThe best way to see all the different file formats is to run a small pipeline and see which files we encounter along the way. The pipeline is roughly the same steps you'll do in the variant-calling part of the course, so for now we'll stick with the dummy pipeline which some of you might have encoutered in the [extra material](lab_uppmax_pipeline.html) for the UPPMAX exercise.\n\nThe programs in the dummy pipeline does not actually do any analysis but they work the same way as the real deal, although slightly simplified, to get you familiar with how to work with analysis programs. The data is from a sequencing of the adenovirus genome, which is tiny compared to the human genome (36kb vs 3gb).\n\nThe starting point of the pipeline are fresh reads from the sequencing machine in fastq format, and a reference genome in fasta format. The goal of the exercise is to look at our aligned reads in a genome viewer together with the annotations of the adenovirus genome.\n\nFirst, let's go through the steps of the pipeline:\n\n* **Build an index for the reference genome.** This will speed up the alignment process. Not possible to do the analysis without it.\n* **Align the reads.**\n* **Convert the SAM file to a BAM file.** We want to use the space efficiently.\n* **Sort the BAM file.** We have to sort it to be able to index it.\n* **Index the BAM file.** We have to index it to make it fast to access the data in the file.\n* **View the aligned data together with the annotations.**\n\nThe first thing you usually do is to load the modules for the programs you want to run. During this exercise we'll only run my dummy scripts that don't actually do any analysis, so they don't have a module of their own. What we can do instead is to manually do what module loading usually does: to modify the **`$PATH` variable**.\n\nThe `$PATH` variable specifies directories where the computer should look for programs. For instance, when you type `nano`, how does the computer know which program to start? You gave it the name `nano`, but that could refer to any file named nano in the computer, yet it starts the correct one every time. The answer is that it looks in the directories stored in the `$PATH` variable.\n\nTo see which directories that are available by default, type\n\n```bash\n$ echo $PATH\n```\n\nIt should give you something like this, a list of directories, separated by colon signs:\n\n```bash\ndahlo@rackham2 work $ echo $PATH\n/home/dahlo/perl//bin/:/home/dahlo/.pyenv/shims:/home/dahlo/.pyenv/bin:\n/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:\n/sbin:/opt/thinlinc/bin:/sw/uppmax/bin:/home/dahlo/usr/bin\n```\n\nTry loading a module, and then look at the `$PATH` variable again. You'll see that there are a few extra directories there now, after the module has been loaded.\n\n```bash\ndahlo@rackham2 work $ module load bioinfo-tools samtools/1.10\ndahlo@rackham2 work $ echo $PATH\n/sw/apps/bioinfo/samtools/1.10/rackham/bin:/home/dahlo/perl/bin:/home/dahlo/.pyenv/shims:\n/home/dahlo/.pyenv/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:\n/usr/sbin:/sbin:/opt/thinlinc/bin:/sw/uppmax/bin:/home/dahlo/usr/bin\n```\n\nTo pretend that we are loading a module, we will just add a the directory containing my dummy scripts to the `$PATH` variable, and it will be like we loaded the module for them.\n\n```bash\n$ export PATH=$PATH:/sw/courses/ngsintro/linux/uppmax_pipeline_exercise/dummy_scripts\n```\n\nThis will set the `$PATH` variable to whatever it is at the moment, and add a directory at the end of it. Note the lack of a dollar sign in front of the variable name directly after `export`. You don't use dollar sign when  **assigning** values to variables, and you always use dollar signs when **getting** values from variables.\n\n::: {.alert .alert-warning}\n\n{{< fa exclamation-circle >}} **Important**\n\nThe export command affects only the terminal you type it in. If you have 2 terminals open, only the terminal you typed it in will have a modified path. If you close that terminal and open a new one, it will not have the modified path.\n\n:::\n\n### Build index\n\n1. **Build an index for the reference genome.**\n2. Align the reads.\n3. Convert the SAM file to a BAM file.\n4. Sort the BAM file.\n5. Index the BAM file.\n6. View the aligned data together with the annotations.\n\nAll aligners will have to index the reference genome you are aligning your data against. This is only done once per reference genome, and then you reuse that index whenever you need it. All aligners have their own kind of index unfortunately, so you will have to build one index for each aligner you want to use. In this lab, we will use the dummy aligher called `align_reads`, and we will build a index using it's indexing progam, called `reference_indexer`.\n\nFirst, have a look in the **0_ref** folder\n\n```bash\n$ ll 0_ref\n```\n\nYou should see 2 files: the fasta file, the gtf file. Have a look at each of them with `less`, just to see how they look inside. To do the actual indexing of the genome:\n\n{{< fa clipboard-list >}} Run reference_indexer.\n\n```bash\nSyntax: reference_indexer -r <name of the fasta file you want to index>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ reference_indexer -r 0_ref/ad2.fa'))\n```\n\nSince the genome is so small this should only take a second or so. The human genome will probably take a couple of hours. Look in the **0_ref folder** again and see if anything has changed.\n\n```bash\n$ ll 0_ref\n```\n\nThe new file you see is the index file created by **reference_indexer**. This index is in the same format as you would get from the real program **samtools**. Try viewing the index file with `less` and see how it looks. The samtools type of index contains one row per fasta record in the reference file. In this case, there is only one record for the adenovirus genome, and it's called `ad2` in the fasta file. The human reference genome typically have one record per chromosome, so a index of the human genome would then have 24 rows.\n\nThe numbers after the record name specifies how many bases the record has, how far into the file (in bytes) the record starts, the number of bases on each line in the record, and how many bytes each line takes up in the file.\nUsing this information the program can quickly jump to the start location of each record, without having to read the file from the first row every time.\n\nOther aligners might use more complex indexing of the file to speed up the alignment process even further, e.g. creating an index over where it can find all possible \"words\" that you can form with 5 or so bases, making it easier to find possible matching sites for reads. If the read starts with `ATGTT` you can quickly look in the index and see all places in the geonome that contains this word and start looking if the rest of the read matches the area around the word.\n\nThis greatly decreases the number of places you have to look when looking for a match. These types of indexes usually take a long time to create (5+ hours maybe), but since you only have to do it once per reference genome it's easily worth it, seeing how the alignment process probably would take 100s of hours without the index, instead of 6-12 hours.\n\nWe are now ready to align our reads.\n\n### Align reads\n\n1. Build an index for the reference genome.\n2. **Align the reads.**\n3. Convert the SAM file to a BAM file.\n4. Sort the BAM file.\n5. Index the BAM file.\n6. View the aligned data together with the annotations.\n\n{{< fa clipboard-list >}} Align reads using **align_reads**, naming the output file **ad2.sam**, placed in the **1_alignment** folder.\n\n```bash\nSyntax: align_reads -r <reference genome> -i <fastq file with reads> -o <name of the output file>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ align_reads -r 0_ref/ad2.fa -i 0_seq/ad2.fq -o 1_alignment/ad2.sam'))\n```\n\nThis will create a SAM file in **1_alignment** called **ad2.sam**. Have a look at it with less. If you think the file looks messy, add a `-S` after less to make it stop wrapping long lines, `less -S 1_alignment/ad2.sam` and scroll sideways using the arrow keys. As you can see there is one row per aligned read in this file. Each row contains information about the read, like the name of the read, where in the reference genome it aligned, and also a copy of the reads sequence and quality score, among other things.\n\n### SAM to BAM\n\n1. Build an index for the reference genome.\n2. Align the reads.\n3. **Convert the SAM file to a BAM file.**\n4. Sort the BAM file.\n5. Index the BAM file.\n6. View the aligned data together with the annotations.\n\n{{< fa clipboard-list >}} The next step is to convert the SAM file to a BAM file. This is more or less just compressing the file, like creating a zip file. To do that we will use the dummy program **sambam_tools**, telling it we want to convert a file to BAM (**-f bam**), which file we want to convert (**-i**), where it should save the resulting BAM file (**-o**). Save the BAM file in the **2_bam** folder and name it **ad2.bam**.\n\n```bash\nSyntax: sambam_tool -f bam -i <sam file> -o <bam>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ sambam_tool -f bam -i 1_alignment/ad2.sam -o 2_bam/ad2.bam'))\n```\n\nHave a look in the **2_bam** folder.\n\n```bash\n$ ll 2_bam\n```\n\nThe created BAM file is an exact copy of the SAM file, but stored in a much more efficient format. Aligners usually have an option to output BAM format directly, saving you the trouble to convert it yourself, but not all tools can do this (they really should though). Have a look at the difference in file size, though in this example it's quite an extreme difference (2.9 MB vs 0.3 MB). The quality score of all reads is the same (BBBBBBBBB..), and files with less differences are easier to compress. Usually the BAM file is about 25% of the size of the SAM file.\n\nSince the BAM format is a binary format we can't look at it with `less`. We would have to use a tool, like **samtools** which you will probably see later in the week, to first convert the file back to a SAM file before we can read it. In that case we can just look at the SAM file before converting it since they will be the same.\n\n### Sort & index BAM\n\n1. Build an index for the reference genome.\n2. Align the reads.\n3. Convert the SAM file to a BAM file.\n4. **Sort the BAM file.**\n5. **Index the BAM file.**\n6. View the aligned data together with the annotations.\n\nA BAM file is taking up much less space than the SAM file, but we can still improve performance. An indexed BAM file is infinitely faster for programs to work with, but before we can index it, we have to sort it since it's not possible to index an unsorted file in any meaningful way.\n\n{{< fa clipboard-list >}} To sort the BAM file we'll use the **sambam_tool** again, but specifying a different function, **-f sort** instead. Tell it to store the sorted BAM file in the **3_sorted** folder and name the file **ad2.sorted.bam**\n\n```bash\nSyntax: sambam_tool -f sort -i <unsorted bam file> -o <sorted bam file>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ sambam_tool -f sort -i 2_bam/ad2.bam -o 3_sorted/ad2.sorted.bam'))\n```\n\nThis will sort the **ad2.bam** file and create a new BAM file which is sorted, called **ad2.sorted.bam**.\n\n{{< fa clipboard-list >}} Now when we have a sorted BAM file, we can index it. Use the command\n\n```bash\nSyntax: sambam_tool -f index -i <sorted bam file>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ sambam_tool -f index -i 3_sorted/ad2.sorted.bam'))\n```\n\nThis will create an index named **ad2.sorted.bam.bai** in the same folder as the **ad2.sorted.bam** file is located. It's nicer to have the **.bam** and **.bai** named to the same \"prefix\", so rename the **.bai** file to not have the **.bam** in its name.\n\n```bash\n$ mv 3_sorted/ad2.sorted.bam.bai 3_sorted/ad2.sorted.bai\n```\n\n### View in a genome viewer\n\n1. Build an index for the reference genome.\n2. Align the reads.\n3. Convert the SAM file to a BAM file.\n4. Sort the BAM file.\n5. Index the BAM file.\n6. **View the aligned data together with the annotations.**\n\nNow that we have to data aligned and prepared for easy access, we will view it in a genome viewer together with the annotations for the genome. Have a look at the annotations file with `less`.\n\n```bash\n$ less -S 0_ref/ad2.gtf\n```\n\nThe **-S** will tell less to not wrap the lines, and instead show one line per line. If the line is longer than the window, you can user the left and right arrow to scroll to the left and right. Many tabular files are much more readable when using the `-S` option. Try viewing the file without it and see the difference.\n\nTo view the file, we will use the program **IGV** (Integrated Genome Viewer). Before we can do this, we have to load the module for IGV.\n\n{{< fa lightbulb >}} If you are using a Mac you might have to install the program [XQuartz](https://www.xquartz.org/), if you have not already installed that program. By using `-Y` in your ssh command you enable graphical transfer over ssh, but you will also have to have a program able to receive the graphics in order to display it.\n\n```bash\n$ module load bioinfo-tools IGV/2.4.2\n```\n\nStart it by typing the following command (now we'll find out if you used `-Y` in all your ssh connections!):\n\n```bash\n$ igv.sh\n```\n\n::: {.callout-tip}\n\nIf you notice that IGV over Xforwarding is excruciatingly slow, you can try to use the web based ThinLinc client instead. Unfortunately this requires you to have set up a two factor authentification (2FA) with UPPMAX, so it's something you can try on your own. [Instructions for setting up the 2FA at UPPMAX](https://www.uppmax.uu.se/support/user-guides/setting-up-two-factor-authentication/). When you are all set up, go to the address [https://rackham-gui.uppmax.uu.se](https://rackham-gui.uppmax.uu.se) and login with your normal UPPMAX username and password together with your 2FA (described at the login screen). This will get you a remote desktop on one of the login nodes, and you can open a terminal and run IGV there instead. Once IGV is started, either using Xforwarding or the remote desktop in your web browser, we are ready to go.\n:::\n\nThere are 3 files we have to load in IGV.\n\nThe first is the reference genome. Press the menu button located at **\"Genomes - Load Genome from File...\"** and find your reference genome in **0_ref/ad2.fa**. If you are having trouble finding your files, note that IGV always starts in your home directory. Use the dropdown menu at the top to navigate to **`r paste0(\"/proj/\",upid,\"/nobackup/...\")`**.\n\nThe second file you have to load is the reads. Press the menu button **\"File - Load from File...\"** and select your **3_sorted/ad2.sorted.bam**.\n\nThe last file you have to load is the annotation data. Press **\"File - Load from File...\"** again and select you annotation file in **0_ref/ad2.gtf**.\n\nThis will show you the reference genome, how all the reads are aligned to it, and all the annotation data. Try zooming in on an area and have a look at the reads and annotations. The figures you see in the picture are all derived from the data in the files you have given it.\n\nAt the top of the window you have the overview of the current chromosome you are looking at, which tells you the scale you are zoomed at for the moment. When you zoom in you will see a red rectangle apper which shows you which portion of the chromosome you are looking at. Just below the scale you'll see the coverage graph, which tells you how many reads cover each position along the reference genome. The colored bands you see here and there are SNPs, i.e. positions where the reads of your sample does not match the reference genome.\n\nAll the reads, the larger area in the middle of the window, are drawn from the data in the BAM file using the chromosome name, the starting position and the ending position of each read. When you zoom in more you will be able to see individual reads and how they are aligned. The annotation in GTF format are all plotted using the data in the GTF file, visible just under all the reads, are shown as blue rectangles.\n\nThe reference genome, a fasta file containing the DNA sequence of the reference genome, is visible at the bottom of the window if you zoom to the smallest level so you can see the bases of the genome.\n\n## Create a CRAM file\n\nThe CRAM format is even more efficient than the BAM format. To create a CRAM file we'll have to use **samtools**, so we will load the module for it.\n\n```bash\n$ module load bioinfo-tools samtools/1.10\n```\n\n{{< fa clipboard-list >}} Tell samtools that you want CRAM output (**`-C`**) and specify which reference genome it should use to do the CRAM conversion (**`-T`**)\n\n```bash\nSyntax: samtools view -C -T <reference genome> -o <name of cram file> <bam file to convert>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ samtools view -C -T 0_ref/ad2.fa -o 4_cram/ad2.cram 3_sorted/ad2.sorted.bam'))\n```\n\nCompare the sizes of the convered BAM file and the newly created CRAM file:\n\n```bash\n$ ll -h 3_sorted/ad2.sorted.bam 4_cram/ad2.cram\n```\n\nThis will list both the files, and print the file size in a human readable format (**`-h`**). The CRAM file is roughly 1/3 of the size of the BAM file. This is probably because all the reads in the simulated data has the same quality value (BBBBBBBBBB). Fewer types of quality values are easier to compress, hence this amazing compression ratio. Real data will have much more diverse quality scores, and the CRAM file would be pethaps 70-80% of the original BAM file.\n\n::: {.callout-note}\n\n## Optional\n\nIf you have been fast to finish this lab and you still have time left (or just can't get enough of linux stuff), please have a look at the [advanced linux tutorial](lab_linux_advanced.html) where you can learn the basics in bash programming using variables, loops and control statements.\n\n:::\n","srcMarkdownNoYaml":"\n\n```{r,eval=TRUE,include=FALSE}\nlibrary(yaml)\nlibrary(here)\nupid <- yaml::read_yaml(here(\"_quarto.yml\"))$uppmax_project\n```\n\n::: {.callout-note}\nIn code blocks, the dollar sign (`$`) is not to be printed. The dollar sign is usually an indicator that the text following it should be typed in a terminal window.\n:::\n\n## Connect to UPPMAX\n\nThe first step of this lab is to open a ssh connection to UPPMAX. Please refer to [**Connecting to UPPMAX**](topics/other/lab_connect.html) for instructions. Once connected to UPPMAX, return here and continue reading the instructions below.\n\n## Logon to a node\n\nUsually you would do most of the work in this lab directly on one of the login nodes at UPPMAX, but we have arranged for you to have one core each for better performance. This was covered briefly in the lecture notes.\n\n```{r,echo=FALSE,comment=\"\",class.output=\"bash\"}\ncat(paste0(\"$ salloc -A \",upid,\" -t 07:00:00 -p core -n 1 --no-shell &\"))\n```\n\ncheck which node you got (replace **username** with your UPPMAX username)\n\n```bash\n$ squeue -u username\n```\n\nshould look something like this\n\n```bash\ndahlo@rackham2 work $ squeue -u dahlo\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           3132376      core       sh    dahlo  R       0:04      1 r292\ndahlo@rackham2 work $\n```\n\nwhere **r292** is the name of the node I got (yours will probably be different).\nNote the numbers in the Time column. They show for how long the job has been running. When it reaches the time limit you requested (7 hours in this case) the session will shut down, and you will lose all unsaved data. Connect to this node from within UPPMAX.\n\n```bash\n$ ssh -Y r292\n```\n\n{{< fa lightbulb >}} There is a UPPMAX specific tool called `jobinfo` that supplies the same kind of information as `squeue` that you can use as well (`$ jobinfo -u username`).\n\n## Copy lab files\n\nNow you will need some files. To avoid all the course participants editing the same file all at once, undoing each other's edits, each participant will get their own copy of the needed files. The files are located in the folder `/sw/courses/ngsintro/linux/filetypes`\n\nNext, copy the lab files from this folder. `-r` means recursively, which means all the files including sub-folders of the source folder. Without it, only files directly in the source folder would be copied, NOT sub-folders and files in sub-folders.\n\n{{< fa lightbulb >}} Remember to use tab-complete to avoid typos and too much writing.\n\n```{r,echo=FALSE,comment=\"\",class.output=\"bash\"}\ncat(\"$ cp -r <source> <destination>\\n\")\ncat(paste0(\"$ cp -r /sw/courses/ngsintro/linux/filetypes /proj/\",upid,\"/nobackup/username/\"))\n```\n\nHave a look in **`r paste0(\"/proj/\",upid,\"/nobackup/username/\")`**.\n\n```{r,echo=FALSE,comment=\"\",class.output=\"bash\"}\ncat(paste0(\"$ cd /proj/\",upid,\"/nobackup/username/filetypes\\n\"))\ncat(\"$ tree\")\n```\n\nThis will print a file tree, which gives you a nice overview of the folders where you are standing in. As you can see, you have a couple of files and a couple of empty folders. In the **0_ref** folder you have a reference genome in fasta format and annotations for the genome in GTF format. In **0_seq** you have a fastq file containing the reads we will align.\n\n## Run pipeline\n\nThe best way to see all the different file formats is to run a small pipeline and see which files we encounter along the way. The pipeline is roughly the same steps you'll do in the variant-calling part of the course, so for now we'll stick with the dummy pipeline which some of you might have encoutered in the [extra material](lab_uppmax_pipeline.html) for the UPPMAX exercise.\n\nThe programs in the dummy pipeline does not actually do any analysis but they work the same way as the real deal, although slightly simplified, to get you familiar with how to work with analysis programs. The data is from a sequencing of the adenovirus genome, which is tiny compared to the human genome (36kb vs 3gb).\n\nThe starting point of the pipeline are fresh reads from the sequencing machine in fastq format, and a reference genome in fasta format. The goal of the exercise is to look at our aligned reads in a genome viewer together with the annotations of the adenovirus genome.\n\nFirst, let's go through the steps of the pipeline:\n\n* **Build an index for the reference genome.** This will speed up the alignment process. Not possible to do the analysis without it.\n* **Align the reads.**\n* **Convert the SAM file to a BAM file.** We want to use the space efficiently.\n* **Sort the BAM file.** We have to sort it to be able to index it.\n* **Index the BAM file.** We have to index it to make it fast to access the data in the file.\n* **View the aligned data together with the annotations.**\n\nThe first thing you usually do is to load the modules for the programs you want to run. During this exercise we'll only run my dummy scripts that don't actually do any analysis, so they don't have a module of their own. What we can do instead is to manually do what module loading usually does: to modify the **`$PATH` variable**.\n\nThe `$PATH` variable specifies directories where the computer should look for programs. For instance, when you type `nano`, how does the computer know which program to start? You gave it the name `nano`, but that could refer to any file named nano in the computer, yet it starts the correct one every time. The answer is that it looks in the directories stored in the `$PATH` variable.\n\nTo see which directories that are available by default, type\n\n```bash\n$ echo $PATH\n```\n\nIt should give you something like this, a list of directories, separated by colon signs:\n\n```bash\ndahlo@rackham2 work $ echo $PATH\n/home/dahlo/perl//bin/:/home/dahlo/.pyenv/shims:/home/dahlo/.pyenv/bin:\n/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:\n/sbin:/opt/thinlinc/bin:/sw/uppmax/bin:/home/dahlo/usr/bin\n```\n\nTry loading a module, and then look at the `$PATH` variable again. You'll see that there are a few extra directories there now, after the module has been loaded.\n\n```bash\ndahlo@rackham2 work $ module load bioinfo-tools samtools/1.10\ndahlo@rackham2 work $ echo $PATH\n/sw/apps/bioinfo/samtools/1.10/rackham/bin:/home/dahlo/perl/bin:/home/dahlo/.pyenv/shims:\n/home/dahlo/.pyenv/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:\n/usr/sbin:/sbin:/opt/thinlinc/bin:/sw/uppmax/bin:/home/dahlo/usr/bin\n```\n\nTo pretend that we are loading a module, we will just add a the directory containing my dummy scripts to the `$PATH` variable, and it will be like we loaded the module for them.\n\n```bash\n$ export PATH=$PATH:/sw/courses/ngsintro/linux/uppmax_pipeline_exercise/dummy_scripts\n```\n\nThis will set the `$PATH` variable to whatever it is at the moment, and add a directory at the end of it. Note the lack of a dollar sign in front of the variable name directly after `export`. You don't use dollar sign when  **assigning** values to variables, and you always use dollar signs when **getting** values from variables.\n\n::: {.alert .alert-warning}\n\n{{< fa exclamation-circle >}} **Important**\n\nThe export command affects only the terminal you type it in. If you have 2 terminals open, only the terminal you typed it in will have a modified path. If you close that terminal and open a new one, it will not have the modified path.\n\n:::\n\n### Build index\n\n1. **Build an index for the reference genome.**\n2. Align the reads.\n3. Convert the SAM file to a BAM file.\n4. Sort the BAM file.\n5. Index the BAM file.\n6. View the aligned data together with the annotations.\n\nAll aligners will have to index the reference genome you are aligning your data against. This is only done once per reference genome, and then you reuse that index whenever you need it. All aligners have their own kind of index unfortunately, so you will have to build one index for each aligner you want to use. In this lab, we will use the dummy aligher called `align_reads`, and we will build a index using it's indexing progam, called `reference_indexer`.\n\nFirst, have a look in the **0_ref** folder\n\n```bash\n$ ll 0_ref\n```\n\nYou should see 2 files: the fasta file, the gtf file. Have a look at each of them with `less`, just to see how they look inside. To do the actual indexing of the genome:\n\n{{< fa clipboard-list >}} Run reference_indexer.\n\n```bash\nSyntax: reference_indexer -r <name of the fasta file you want to index>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ reference_indexer -r 0_ref/ad2.fa'))\n```\n\nSince the genome is so small this should only take a second or so. The human genome will probably take a couple of hours. Look in the **0_ref folder** again and see if anything has changed.\n\n```bash\n$ ll 0_ref\n```\n\nThe new file you see is the index file created by **reference_indexer**. This index is in the same format as you would get from the real program **samtools**. Try viewing the index file with `less` and see how it looks. The samtools type of index contains one row per fasta record in the reference file. In this case, there is only one record for the adenovirus genome, and it's called `ad2` in the fasta file. The human reference genome typically have one record per chromosome, so a index of the human genome would then have 24 rows.\n\nThe numbers after the record name specifies how many bases the record has, how far into the file (in bytes) the record starts, the number of bases on each line in the record, and how many bytes each line takes up in the file.\nUsing this information the program can quickly jump to the start location of each record, without having to read the file from the first row every time.\n\nOther aligners might use more complex indexing of the file to speed up the alignment process even further, e.g. creating an index over where it can find all possible \"words\" that you can form with 5 or so bases, making it easier to find possible matching sites for reads. If the read starts with `ATGTT` you can quickly look in the index and see all places in the geonome that contains this word and start looking if the rest of the read matches the area around the word.\n\nThis greatly decreases the number of places you have to look when looking for a match. These types of indexes usually take a long time to create (5+ hours maybe), but since you only have to do it once per reference genome it's easily worth it, seeing how the alignment process probably would take 100s of hours without the index, instead of 6-12 hours.\n\nWe are now ready to align our reads.\n\n### Align reads\n\n1. Build an index for the reference genome.\n2. **Align the reads.**\n3. Convert the SAM file to a BAM file.\n4. Sort the BAM file.\n5. Index the BAM file.\n6. View the aligned data together with the annotations.\n\n{{< fa clipboard-list >}} Align reads using **align_reads**, naming the output file **ad2.sam**, placed in the **1_alignment** folder.\n\n```bash\nSyntax: align_reads -r <reference genome> -i <fastq file with reads> -o <name of the output file>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ align_reads -r 0_ref/ad2.fa -i 0_seq/ad2.fq -o 1_alignment/ad2.sam'))\n```\n\nThis will create a SAM file in **1_alignment** called **ad2.sam**. Have a look at it with less. If you think the file looks messy, add a `-S` after less to make it stop wrapping long lines, `less -S 1_alignment/ad2.sam` and scroll sideways using the arrow keys. As you can see there is one row per aligned read in this file. Each row contains information about the read, like the name of the read, where in the reference genome it aligned, and also a copy of the reads sequence and quality score, among other things.\n\n### SAM to BAM\n\n1. Build an index for the reference genome.\n2. Align the reads.\n3. **Convert the SAM file to a BAM file.**\n4. Sort the BAM file.\n5. Index the BAM file.\n6. View the aligned data together with the annotations.\n\n{{< fa clipboard-list >}} The next step is to convert the SAM file to a BAM file. This is more or less just compressing the file, like creating a zip file. To do that we will use the dummy program **sambam_tools**, telling it we want to convert a file to BAM (**-f bam**), which file we want to convert (**-i**), where it should save the resulting BAM file (**-o**). Save the BAM file in the **2_bam** folder and name it **ad2.bam**.\n\n```bash\nSyntax: sambam_tool -f bam -i <sam file> -o <bam>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ sambam_tool -f bam -i 1_alignment/ad2.sam -o 2_bam/ad2.bam'))\n```\n\nHave a look in the **2_bam** folder.\n\n```bash\n$ ll 2_bam\n```\n\nThe created BAM file is an exact copy of the SAM file, but stored in a much more efficient format. Aligners usually have an option to output BAM format directly, saving you the trouble to convert it yourself, but not all tools can do this (they really should though). Have a look at the difference in file size, though in this example it's quite an extreme difference (2.9 MB vs 0.3 MB). The quality score of all reads is the same (BBBBBBBBB..), and files with less differences are easier to compress. Usually the BAM file is about 25% of the size of the SAM file.\n\nSince the BAM format is a binary format we can't look at it with `less`. We would have to use a tool, like **samtools** which you will probably see later in the week, to first convert the file back to a SAM file before we can read it. In that case we can just look at the SAM file before converting it since they will be the same.\n\n### Sort & index BAM\n\n1. Build an index for the reference genome.\n2. Align the reads.\n3. Convert the SAM file to a BAM file.\n4. **Sort the BAM file.**\n5. **Index the BAM file.**\n6. View the aligned data together with the annotations.\n\nA BAM file is taking up much less space than the SAM file, but we can still improve performance. An indexed BAM file is infinitely faster for programs to work with, but before we can index it, we have to sort it since it's not possible to index an unsorted file in any meaningful way.\n\n{{< fa clipboard-list >}} To sort the BAM file we'll use the **sambam_tool** again, but specifying a different function, **-f sort** instead. Tell it to store the sorted BAM file in the **3_sorted** folder and name the file **ad2.sorted.bam**\n\n```bash\nSyntax: sambam_tool -f sort -i <unsorted bam file> -o <sorted bam file>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ sambam_tool -f sort -i 2_bam/ad2.bam -o 3_sorted/ad2.sorted.bam'))\n```\n\nThis will sort the **ad2.bam** file and create a new BAM file which is sorted, called **ad2.sorted.bam**.\n\n{{< fa clipboard-list >}} Now when we have a sorted BAM file, we can index it. Use the command\n\n```bash\nSyntax: sambam_tool -f index -i <sorted bam file>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ sambam_tool -f index -i 3_sorted/ad2.sorted.bam'))\n```\n\nThis will create an index named **ad2.sorted.bam.bai** in the same folder as the **ad2.sorted.bam** file is located. It's nicer to have the **.bam** and **.bai** named to the same \"prefix\", so rename the **.bai** file to not have the **.bam** in its name.\n\n```bash\n$ mv 3_sorted/ad2.sorted.bam.bai 3_sorted/ad2.sorted.bai\n```\n\n### View in a genome viewer\n\n1. Build an index for the reference genome.\n2. Align the reads.\n3. Convert the SAM file to a BAM file.\n4. Sort the BAM file.\n5. Index the BAM file.\n6. **View the aligned data together with the annotations.**\n\nNow that we have to data aligned and prepared for easy access, we will view it in a genome viewer together with the annotations for the genome. Have a look at the annotations file with `less`.\n\n```bash\n$ less -S 0_ref/ad2.gtf\n```\n\nThe **-S** will tell less to not wrap the lines, and instead show one line per line. If the line is longer than the window, you can user the left and right arrow to scroll to the left and right. Many tabular files are much more readable when using the `-S` option. Try viewing the file without it and see the difference.\n\nTo view the file, we will use the program **IGV** (Integrated Genome Viewer). Before we can do this, we have to load the module for IGV.\n\n{{< fa lightbulb >}} If you are using a Mac you might have to install the program [XQuartz](https://www.xquartz.org/), if you have not already installed that program. By using `-Y` in your ssh command you enable graphical transfer over ssh, but you will also have to have a program able to receive the graphics in order to display it.\n\n```bash\n$ module load bioinfo-tools IGV/2.4.2\n```\n\nStart it by typing the following command (now we'll find out if you used `-Y` in all your ssh connections!):\n\n```bash\n$ igv.sh\n```\n\n::: {.callout-tip}\n\nIf you notice that IGV over Xforwarding is excruciatingly slow, you can try to use the web based ThinLinc client instead. Unfortunately this requires you to have set up a two factor authentification (2FA) with UPPMAX, so it's something you can try on your own. [Instructions for setting up the 2FA at UPPMAX](https://www.uppmax.uu.se/support/user-guides/setting-up-two-factor-authentication/). When you are all set up, go to the address [https://rackham-gui.uppmax.uu.se](https://rackham-gui.uppmax.uu.se) and login with your normal UPPMAX username and password together with your 2FA (described at the login screen). This will get you a remote desktop on one of the login nodes, and you can open a terminal and run IGV there instead. Once IGV is started, either using Xforwarding or the remote desktop in your web browser, we are ready to go.\n:::\n\nThere are 3 files we have to load in IGV.\n\nThe first is the reference genome. Press the menu button located at **\"Genomes - Load Genome from File...\"** and find your reference genome in **0_ref/ad2.fa**. If you are having trouble finding your files, note that IGV always starts in your home directory. Use the dropdown menu at the top to navigate to **`r paste0(\"/proj/\",upid,\"/nobackup/...\")`**.\n\nThe second file you have to load is the reads. Press the menu button **\"File - Load from File...\"** and select your **3_sorted/ad2.sorted.bam**.\n\nThe last file you have to load is the annotation data. Press **\"File - Load from File...\"** again and select you annotation file in **0_ref/ad2.gtf**.\n\nThis will show you the reference genome, how all the reads are aligned to it, and all the annotation data. Try zooming in on an area and have a look at the reads and annotations. The figures you see in the picture are all derived from the data in the files you have given it.\n\nAt the top of the window you have the overview of the current chromosome you are looking at, which tells you the scale you are zoomed at for the moment. When you zoom in you will see a red rectangle apper which shows you which portion of the chromosome you are looking at. Just below the scale you'll see the coverage graph, which tells you how many reads cover each position along the reference genome. The colored bands you see here and there are SNPs, i.e. positions where the reads of your sample does not match the reference genome.\n\nAll the reads, the larger area in the middle of the window, are drawn from the data in the BAM file using the chromosome name, the starting position and the ending position of each read. When you zoom in more you will be able to see individual reads and how they are aligned. The annotation in GTF format are all plotted using the data in the GTF file, visible just under all the reads, are shown as blue rectangles.\n\nThe reference genome, a fasta file containing the DNA sequence of the reference genome, is visible at the bottom of the window if you zoom to the smallest level so you can see the bases of the genome.\n\n## Create a CRAM file\n\nThe CRAM format is even more efficient than the BAM format. To create a CRAM file we'll have to use **samtools**, so we will load the module for it.\n\n```bash\n$ module load bioinfo-tools samtools/1.10\n```\n\n{{< fa clipboard-list >}} Tell samtools that you want CRAM output (**`-C`**) and specify which reference genome it should use to do the CRAM conversion (**`-T`**)\n\n```bash\nSyntax: samtools view -C -T <reference genome> -o <name of cram file> <bam file to convert>\n```\n\n```{r,echo=FALSE,accordion=TRUE,class.output=\"bash\",comment='',results='markup'}\ncat(paste0('$ samtools view -C -T 0_ref/ad2.fa -o 4_cram/ad2.cram 3_sorted/ad2.sorted.bam'))\n```\n\nCompare the sizes of the convered BAM file and the newly created CRAM file:\n\n```bash\n$ ll -h 3_sorted/ad2.sorted.bam 4_cram/ad2.cram\n```\n\nThis will list both the files, and print the file size in a human readable format (**`-h`**). The CRAM file is roughly 1/3 of the size of the BAM file. This is probably because all the reads in the simulated data has the same quality value (BBBBBBBBBB). Fewer types of quality values are easier to compress, hence this amazing compression ratio. Real data will have much more diverse quality scores, and the CRAM file would be pethaps 70-80% of the original BAM file.\n\n::: {.callout-note}\n\n## Optional\n\nIf you have been fast to finish this lab and you still have time left (or just can't get enough of linux stuff), please have a look at the [advanced linux tutorial](lab_linux_advanced.html) where you can learn the basics in bash programming using variables, loops and control statements.\n\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"left","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":false,"wrap":"none","default-image-extension":"png","to":"html","filters":["../../assets/custom.lua","reveal-header","lightbox"],"include-in-header":["../../assets/fonts/head.html"],"toc":true,"toc-depth":4,"number-sections":true,"output-file":"lab_linux_filetypes.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","bibliography":["../../references.bib"],"csl":"../../apa.csl","knitr":{"opts_chunk":{"results":"hold"}},"uppmax_project":"snic2023-xx-xxxx","nsc_project":"snic2023-xx-xxxx","uppmax_res_1":"snic2023-xx-xxxx_1","uppmax_res_2":"snic2023-xx-xxxx_2","uppmax_res_3":"snic2023-xx-xxxx_3","uppmax_res_4":"snic2023-xx-xxxx_4","uppmax_res_5":"snic2023-xx-xxxx_5","location":"uppsala","assistants":["AJ: Anna Johansson","BV: Bj√∂rn Viklund","DA: Dag Ahren","FB: Franziska Bonath","JH: Jason Hill","JB: Joakim Bygdell","JA: Juliana Assis","KL: Katarina Lejonlid","KB: Kristina Benevides","LK: Linda K√∂hn","LV: Louella Vasquez","MD: Martin Dahl√∂","MG: Maxime Garcia","ML: Malin Larsson","MM: Markus Mayrhofer","NN: Nina Norgren","OVP: Olga Vinnere Pettersson","PA: Prasoon Agarwal","PP: Paul Pyl","RF: Roy Francis","VVH: Vincent van Hoef","SD: Sebastian DiLorenzo"],"schedule_message":"Coffee breaks are planned for approximately 10:00 and 14:30 every day.","colors":{"primary":"#95b540","secondary":"#E9F2D1"},"packages":{"packages_cran_student":["BiocManager","remotes","dplyr","ggplot2","pheatmap","stringr","tidyr"],"packages_bioc_student":["DESeq2","edgeR","goseq","GO.db","org.Mm.eg.db","reactome.db"],"packages_github_student":null,"packages_cran_repo":["bookdown","captioner","here","htmlTable","knitr","leaflet","lubridate","markdown","pagedown","yaml"],"packages_bioc_repo":null,"packages_github_repo":null},"quarto-required":">=1.2.2","theme":"../../assets/css/custom.scss","smooth-scroll":true,"toc-location":"right","number-depth":4,"code-copy":true,"title-block-banner":"#E9F2D1","callout-icon":false,"date":"last-modified","date-format":"DD-MMM-YYYY","lightbox":{"match":"auto"},"title":"Filetypes","subtitle":"Common filetypes In bioinformatics","author":"Martin Dahl√∂"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html","revealjs"]}